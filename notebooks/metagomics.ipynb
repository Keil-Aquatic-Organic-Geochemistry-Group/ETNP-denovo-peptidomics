{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 26 15:37:26 PDT 2018\r\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuesday, June 26, 2018 ###\n",
    "\n",
    "This notebook is to document my use of the MetaGOmics web application (http://www.yeastrc.org/metagomics/home.do) to perform a peptide-based functional and taxonomic analysis of my metaproteomic data, as described in [Riffle et al., 2018](https://www.ncbi.nlm.nih.gov/pubmed/29280960). The MetaGOmics algorithim is pretty close to Unipept in its approach to a peptide-based least common ancestor evaluation (LCA) that is tied to the UniProtKB database, but it also does a similar evaluation of protein functionality using GO terms from the protein annotations, and it also uses spetral counts to approach some quanitiation of these analyses.\n",
    "\n",
    "The input needed for MetaGOmics:\n",
    "\n",
    "- the queried sequence database in FASTA format. It's noted in the Riffle paper that one only needs a FASTA file containing the proteins matched by any of the uploaded peptides - hence there's some trimming that will make the analysis much quicker. To achieve this I'm uploading the exported FASTA from PEAKS 8.5 Spider searches. This was simple for PEAKS output, but apparently there's some tips for this trimming in the MetaGOmics's GitHub repo\n",
    "\n",
    "- a text file containing the identified peptides and their corresponding spectral counts. Though, it would work just as well to use spectral areas over spectral counts, it's a relative comparison (and would compare a peptide's spectral area to the total, just as the number of spectral counts attributed to a peptide would be compared to the total number of spectral counts for all peptides).\n",
    "\n",
    "I went to MetaGOmics and uploaded ja2-proteins.fasta in the web application and named it _2017 P2 100 m suspended (JA2)_ I chose to use the SwissProt (Unisprot) database for the GO annotations database and I selected a for the BLAST filters: 1E-10, using the top hit only. I recieved an email several seconds later with a link to a page where I could access the database I'd set up and load peptide lists. It looks like this: ![metagomics database page screengrab]( https://raw.githubusercontent.com/MeganEDuffy/2017-etnp/master/images/06.26.18-metgomics-ss.png)\n",
    "\n",
    "Then I need to actually upload the peptide sequences and their corresponding spectral counts (or areas, I chose counts to start). I took the Spider output xlxs file I'd made from the PEAKS exported .csv, and I just made a new Excel file containing the sequences and the # spectra columns, with no headers. It looked like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IVVGGPYSSVSDAASVLDGSQK\t7\r",
      "\r\n",
      "IVVGGPYSSVSDAASSLDSSQK\t6\r",
      "\r\n",
      "AIQQQIENPLAQQILSGELVPGK\t6\r",
      "\r\n",
      "LPQVEGTGGDVQPSQDLVR\t13\r",
      "\r\n",
      "QAVSADSSGSFIGGAELASLK\t7\r",
      "\r\n",
      "LGEHNIDVLEGNEQFINAAK\t11\r",
      "\r\n",
      "YLGSTGGLLNSAETEEK\t6\r",
      "\r\n",
      "YIGSTGGLLNSAETEEK\t6\r",
      "\r\n",
      "AISADSSGGFIGGAELSQLK\t3\r",
      "\r\n",
      "AGAGDDEVNAGSGDDIVR\t3\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head /Users/meganduffy/Documents/git-repos/2017-etnp/data/ja1-ja6/MED_ETNP_JA2_uwpr201704_SPIDER_19/ja2-metagomics-input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I needed to have it saved as tab delimted (.txt). When I tried saving it as a .csv, I didn't get any meaninggul output (no error messages, just no matched GO terms for any peptides). Then I got an email saying I could view my data. You can see that the two (one failed .csv, one suscessful .txt uploads look like in the screengrab above). When I click on the GO annotation download button for the sucessful one (100 m suspended), I get this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
